---
title: "aics: chap2"
---


---

**1) Llama 3 相较于其前代 LLaMA 和 Llama 2 有哪些主要性能提升？**

- **更大的训练数据规模**：Llama 3 使用了数万亿 token，数据覆盖更广，包含更多代码、多语言语料。
    
- **模型架构优化**：改进了注意力机制和归一化方式，提升长上下文建模能力。
    
- **推理能力增强**：在数学、逻辑推理、代码等任务上性能大幅提高。
    
- **更好的对齐（alignment）**：通过强化 RLHF（人类反馈强化学习）和安全调优，使其在安全性、遵循指令方面表现更好。
    

---

**2) Llama 3.2 在训练过程中使用了哪些新技术以提高训练效率？**

- **混合精度训练（FP16 + bfloat16）**，提高计算效率同时保持稳定性。
    
- **流水线并行与张量并行结合**，充分利用硬件加速。
    
- **数据去重与高质量筛选**，减少噪声样本对训练收敛的干扰。
    
- **Curriculum learning（课程式训练）**，先在通用语料上训练，再逐步加入代码、推理等数据。
    

---

**3) Llama 3.2 和 Llama 3.1 之间有什么区别？**

- **模型规模更大**：Llama 3.2 的参数数量和数据规模均有扩展。
    
- **分词器改进**（3.2 使用 TikToken，见问题 4）。
    
- **训练效率更高**：3.2 引入了更多优化策略，使收敛更快。
    
- **推理优化**：在代码、数学和多语言任务上相较 3.1 提升明显。
    

---

**4) Llama 3.2 使用的分词器有何不同，为什么选择 tiktoken？**

- **不同点**：Llama 3.1 使用 SentencePiece，而 Llama 3.2 改用 TikToken。
    
- **优势**：
    
    - TikToken 与 OpenAI 生态兼容，支持 BPE（Byte Pair Encoding）+ Unicode，更好地处理多语言和符号。
        
    - 提高 token 利用率，降低平均文本长度，推理效率更高。
        
    - 更稳定的跨语言分词，不会像 SentencePiece 那样对罕见词碎片化严重。
        

---

**5) 相较于 DeepSeek-V2，DeepSeek-V3 在哪些方面改进了稀疏专家模型的性能与稳定性？结合“无辅助损失的负载均衡策略”说明。**

- **改进点**：
    
    - 稀疏 MoE（Mixture of Experts）门控更高效，每个 token 激活更合适的专家，避免负载不均。
        
    - DeepSeek-V3 去掉了辅助均衡损失函数，改用路由器内在优化策略，使训练更稳定。
        
    - 提高了专家利用率，减少计算浪费。
        
- **“无辅助损失的负载均衡”**：传统 MoE 需要额外损失项来约束专家均衡，但可能影响模型收敛。DeepSeek-V3 通过改进的路由策略实现自然均衡，不依赖额外损失，训练效率和稳定性更好。
    

---

**6) DeepSeek-R1-Zero 采用了纯强化学习方式训练语言模型，请分析跳过监督微调阶段的利与弊。**

- **优点**：
    
    - 模型不受人工标注或已有监督数据的偏见限制，探索性更强。
        
    - 可以更贴近最终任务目标（例如强化推理能力）。
        
- **缺点**：
    
    - 训练初期缺乏“语言流畅性”的基础，模型可能生成低质量输出。
        
    - 收敛速度慢，计算开销大。
        
    - 如果奖励函数设计不合理，容易出现模式崩坏或过拟合奖励。
        

---

**7) 蒸馏版 DeepSeek-R1 为何能够在轻量化模型中保持强大的推理能力？其蒸馏策略与数据来源有哪些特点？**

- **蒸馏策略**：
    
    - 采用 **思维链（Chain-of-Thought）蒸馏**，教师模型不仅给答案，还提供中间推理步骤。
        
    - 使用 **奖励蒸馏**（Reward Distillation），结合强化学习奖励信号，将大模型的能力迁移到小模型。
        
- **数据来源特点**：
    
    - 大规模高质量推理数据，包括数学、代码、逻辑推理任务。
        
    - 自动生成 + 人工筛选相结合，保证覆盖面和质量。
        
    - 多样化场景蒸馏，确保小模型在通用和专业任务上都能保持稳定推理性能。
        
